{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1ly1vXkikKZlQUqDSvngMTHcKoRCuwdHs",
      "authorship_tag": "ABX9TyPT0UXevrxyClGQIh6VZSNK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hudada369/fy2020-repo-config/blob/master/Pytorch_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "d3lh3LTpHscF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. 张量的简介与创建（张量及各种创建方式）；\n",
        "2. 张量的基本操作（张量的切分，拼接，索引，变换，数学运算）；\n",
        "3. 玩一个简单的线性回归模型；\n",
        "4. 总结梳理。"
      ],
      "metadata": {
        "id": "Q6_l1DpimHCB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "概念：是多维数组，标量（0维张量），向量（1维度），矩阵的多维扩展\n",
        "Variable 是 torch.autograd 中的数据类型，现在并入了tensor中\n",
        "Tensor的属性包括：\n",
        "1. data（被包装的 Tensor）, \n",
        "2. dtype（张量的数据类型，如 torch.FloatTensor，torch.cuda.FloatTensor，用的最多的一般是 float32 和 int64(torch.long)）, \n",
        "3. shape, （张量的形状，如 (64, 3, 224, 224)）\n",
        "4. device(与数据有关)  \n",
        "5. requires_grad, （指示是否需要梯度，有的不需要梯度）\n",
        "6. grad, （data 的梯度）\n",
        "7. grad_fn, （fn 表示 function 的意思，记录我么创建的创建张量时用到的方法，比如说加法、乘法，这个操作在求导过程需要用到，Tensor 的 Function，是自动求导的关键；）\n",
        "8. is_leaf（指示是否是叶子节点（张量））\n"
      ],
      "metadata": {
        "id": "yH0mZJ-UmQGV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**创建方式：** size传入是括号的形式（3，3）矩阵 （3，）一维张量\n",
        "1. 直接创建 torch.tensor(data,dtype = None,device = None,requeires_grad = False,pinmemory = False) data可以是list,也可以是numpy dtype 这个是指明数据类型，默认与 data 的一致。device 是指明所在的设备  注意：numpy转为tensor需要 torch.from_numpy(ndarry) tensor与原numpy 共享内存\n",
        "2.  依据数值创建，依据size创建大小，torch.zeros(*size,out=None,layout=tensor.strides,device=None,requires_grad=False) layout 是在内粗你的布局形式 **out**是输出张量，将其赋值给另外一个张量，两个张量指向同一个内存\n",
        "3. torch.zeros_like(input, dtype=None, layout=None, device=None, requires_grad=False)：这个是创建与 **input** 同形状的全 0 张量   torch.ones(), torch.ones_like()  # 没like就是输出，like的input是另外的张量，取它的形状\n",
        "4. torch.full(size,full_value,剩下参数和上面一致) fill_value是要填充的值 torch.full_like()\n",
        "5. torch.arange(start,end,step,out,dtype,layout,device,requeires_grad) 创建等差(左闭右开)的张量与numpy一样 \n",
        "6. torch.linspace(参数中steps)：创建均分的 1 维张量， 数值区间 [start, end] 注意这里都是闭区间，和上面的区分 （steps不是步长，而是数列长度） (end-start) / (steps-1)\n",
        "7. torch.logspace(base = 10) 对数均分数列 base应该是底数，剩下的参数和lin一样\n",
        "8. torch.eye(n,m,out，剩余的参数和zeros一样)：创建单位对角矩阵，默认是方阵，n和m对应行数，列数\n",
        "9. 依据概率分布创建张量 torch.normal(mean,std,sieze,out=None)：生成正态分布（高斯分布）， 这个使用的比较多,mean和std分别可以是标量或者张量，所以可以得到4种情况\n",
        "10. 标准正态分布，标准正态分布：torch.**randn**(*size,剩余的参数和zeros一样), torch.randn_like()\n",
        "11. 均匀分布 torch.rand() rand.like() torch.randint(low,high,size,out...) randint_like(low=0,high,size,out...)区间 [low,hight) 生成整数均匀分布」\n",
        "12. 「torch.randperm(n)：生成从 0 - n-1 的随机排列, n 是张量的长度, **经常用来生成一个乱序索引**。 」\n",
        "13. 「torch.bernoulli(input)：以 input 为概率，生成伯努利分布 (0-1 分布，两点分布）， input：概率值」\n"
      ],
      "metadata": {
        "id": "PuNo0apBse7D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GLlX6U0hsfHu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "afrDC0VZsfKW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "LHYHuGzBji3b"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = False\n",
        "if a:\n",
        "  print(2)"
      ],
      "metadata": {
        "id": "8od6xLhOAupD"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arr = np.ones((3,3))\n",
        "print(arr,arr.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggtUODHMji_d",
        "outputId": "762de5d4-a32f-46cc-bcce-7f5404e02edb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 1. 1.]\n",
            " [1. 1. 1.]\n",
            " [1. 1. 1.]] float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.tensor(arr,device = 'cuda')\n",
        "print(t)\n",
        "#不是一个地址"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMWZKxMhjjB6",
        "outputId": "4f5f545a-5c20-451c-869c-8efa3db4a9cc"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[10,  2,  3],\n",
            "        [ 4,  5,  6]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arr = np.array([[1,2,3],[4,5,6]])\n",
        "tor = torch.from_numpy(arr)\n",
        "# 两者共享同一个内存\n",
        "arr[0][0] = 10\n",
        "print(id(arr),id(tor)) # 虽然地址不一样\n",
        "print(arr,tor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSSdF51yjjEX",
        "outputId": "9de6543b-de6c-43ce-8523-3f0f40d29a14"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "140248616474832 140248616474960\n",
            "[[10  2  3]\n",
            " [ 4  5  6]] tensor([[10,  2,  3],\n",
            "        [ 4,  5,  6]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = torch.tensor(3)\n",
        "tor = torch.zeros((3,3),out = t1)\n",
        "print(tor,t1)\n",
        "# 内存地址是一样的\n",
        "print(id(t1),id(tor))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCNNg_avjjGc",
        "outputId": "3f082136-c2d0-4e26-c729-7ac8a2f830f4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]]) tensor([[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]])\n",
            "140248616611568 140248616611568\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = torch.from_numpy(np.array([[1,2,3],[4,5,6]]))\n",
        "t2 = torch.zeros_like(t1)\n",
        "print(t1,t2) # 创建的是和相同形状大小的0张量\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ni3Ye-ewkzM",
        "outputId": "b0835fee-ffed-4dd9-c6ff-f99a7e66ba58"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]]) tensor([[0, 0, 0],\n",
            "        [0, 0, 0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.full((3,3),5)\n",
        "print(t)\n",
        "t = torch.tensor([1,2,3])\n",
        "t = torch.full_like(t,6)\n",
        "print(t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YJH8kI_wk1e",
        "outputId": "8f97eacb-d704-4783-f9d2-7c04d6a706c1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[5, 5, 5],\n",
            "        [5, 5, 5],\n",
            "        [5, 5, 5]])\n",
            "tensor([6, 6, 6])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.arange(1,10,2))\n",
        "print(torch.linspace(1,10,5))\n",
        "print(torch.logspace(1,10,4,10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjorapBlwk36",
        "outputId": "cdaf4159-42ac-4507-b6de-499ac31339fa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 3, 5, 7, 9])\n",
            "tensor([ 1.0000,  3.2500,  5.5000,  7.7500, 10.0000])\n",
            "tensor([1.0000e+01, 1.0000e+04, 1.0000e+07, 1.0000e+10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.eye(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLIAuITu7XaW",
        "outputId": "b091bbc3-537b-4d8d-b299-753eac48cd51"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0.],\n",
              "        [0., 1., 0.],\n",
              "        [0., 0., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 概率分布， 要给定张量的数据类型，float才可以\n",
        "# mean std两者均为标量 从同一个分布抽取size大小的值\n",
        "torch.normal(0,1,size = (4,))\n",
        "# 一个为标量 一个为张量\n",
        "# mean是标量 std是张量 会根据方差的形状大小，产生同样多个分布，每一个分布的均值都是那个标量\n",
        "std = torch.arange(1,5,dtype = torch.float)\n",
        "print(std.dtype)\n",
        "normal2 = torch.normal(1,std)\n",
        "print(normal2)\n",
        "# mean是张量 std是标量 也会根据均值的形状大小，产生同样多个方差相同的分布，从这几个分布中分别取一个值作为结果\n",
        "mean = torch.arange(1,5,dtype = torch.float)\n",
        "print(mean.dtype)\n",
        "normal3 = torch.normal(mean,2)\n",
        "print(normal3)\n",
        "# 两者均为张量 需要均值的个数和方差的个数一样多，分别产生这么多个正太分布，从这里面抽取一个值\n",
        "mean = torch.arange(1,5,dtype = torch.float)\n",
        "std = torch.arange(1,5,dtype = torch.float)\n",
        "# 对应位置的分布\n",
        "normal4 = torch.normal(mean,std)\n",
        "print(normal4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxmznB3Zwk6P",
        "outputId": "3f91403f-7be5-4c54-8a21-0746b4b529cc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float32\n",
            "tensor([-0.0151,  1.1706,  1.1583,  9.3500])\n",
            "torch.float32\n",
            "tensor([ 1.1078, -0.1917,  0.8910,  5.7010])\n",
            "tensor([1.3314, 2.4447, 5.8934, 2.7634])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 标注正太分布\n",
        "t = torch.randn((3,))\n",
        "print(t)\n",
        "t1 = torch.arange(1,6,2)\n",
        "t3 = torch.randn_like(t1,dtype = torch.float)\n",
        "print(t1,t3)\n",
        "# 均匀分布 rand是0，1之间\n",
        "t = torch.rand((1,2))\n",
        "t1 = torch.rand_like(t1,dtype=torch.float)\n",
        "print(t,t1)\n",
        "# 整数均匀分布\n",
        "t = torch.randint(0,5,size=(3,),dtype=torch.float)\n",
        "print(t)\n",
        "# 随机排列分布,乱序索引，参数只能是int 代表张量长度\n",
        "t = torch.randperm(5)\n",
        "print(t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLb_qww6wk8a",
        "outputId": "f21f321d-c4d5-45a7-d590-5b824e03f74c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 1.1397,  0.5378, -0.2602])\n",
            "tensor([1, 3, 5]) tensor([-0.6003, -1.3230,  0.4388])\n",
            "tensor([[0.9731, 0.9473]]) tensor([0.7280, 0.6148, 0.1060])\n",
            "tensor([2., 4., 4.])\n",
            "tensor([0, 4, 1, 3, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **张量的操作**  拼接，切分，索引和变换以及数学运算\n",
        "1. 拼接 stack 会新创建一个维度，然后完成拼接 \n",
        " 1. 「torch.**cat**(tensors, dim=0, out=None)：将张量按**维度 dim 进行拼接**, tensors 表示张量序列， dim 要拼接的维度」\n",
        " 2. 「torch.**stack**(tensors, dim=0, out=None)：在**新创建的维度 dim 上进行拼接**， tensors 表示张量序列， dim 要拼接的维度」\n",
        " 3. 0 是行拼接 1是列拼接\n",
        "2. 切分 张量的切分 \n",
        " 1. **torch.chunk(input, chunks, dim=0)：将张量按维度 dim 进行平均切分，返回值是*张量列表*，注意，如果不能整除， 最后一份张量小于其他张量。chunks 代表要切分的维度。**\n",
        " 2. 「torch.split(tensor, split_size_or_sections, dim=0)：这个也是将张量按维度 dim 切分，但是这个更加强大，**可以指定切分的长度**，split_size_or_sections 为 int 时表示每一份的长度， 为 list 时，按 list 元素切分」但是保证list的长度是那个切分维度的长度\n",
        "\n",
        "3. 张量的索引「torch.index_select(input, dim, index, out=None)：在维度 dim 上，按 index 索引数据，返回值，以 index 索引数据拼接的张量。」\n",
        "\n",
        "4. 「torch.masked_select(input, mask, out=None)：按 mask 中的 True 进行索引，返回值：一维张量。input 表示要索引的张量，mask 表示与 input 同形状的布尔类型的张量。这种情况在选择符合某些特定条件的元素的时候非常好使」，注意这个是返回一维的张量 mask是bool 大小和input一样的形状 返回的是mask中值为True的对应位置的元素一维张量\n",
        "\n",
        "5. 张量的变换  「torch.reshape(input, shape)：变换张量的形状，这个很常用，input 表示要变换的张量，shape表示新张量的形状。但注意，当张量在内存中是连续时，新张量与input共享数据内存」 **shape=(-1,4,2) 第一个-1不知道是否必须**\n",
        "  1. 张量的交换 「torch.transpose(input, dim0, dim1)：交换张量的两个维度, 矩阵的转置常用， 在图像的预处理中常用， dim0 要交换的维度， dim1 表示要交换的问题」\n",
        "  2. 「torch.t(input)：2 维张量的转置， 对矩阵而言，相当于 torch.transpose(inpuot, 0,1)」\n",
        "\n",
        "6. 「torch.squeeze(input, dim=None, out=None)：压缩长度为 1 的维度， dim 若为 None，移除所有长度为 1 的轴，若指定维度，当且仅当该轴长度为 1 时可以被移除」 \n",
        "  1. 「torch.unsqueeze(input, dim, out=None)：依据 dim 扩展维度」"
      ],
      "metadata": {
        "id": "T59uH2lDEPZ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cat是在原基础上拼接，浮点数类型拼接才可以，long 类型拼接会报错\n",
        "t=torch.tensor([[1,2,3],[4,5,6]])\n",
        "print(\"t的shape是：\",t.shape)\n",
        "new_t=torch.cat((t,t),dim=0)\n",
        "print(new_t,t.shape,new_t.shape)\n",
        "# stack 是根据给定的维度新增了一个新的维度，在这个新维度上进行拼接，这个 .stack \n",
        "# 与其说是从新维度上拼接，不太好理解，其实是新加了一个维度 Z 轴，只不过 dim=0 和 dim=1 的视角不同罢了。dim=0 是横向看，dim=1 是纵向看\n",
        "new_t1 = torch.stack((t,t,t),dim=0)\n",
        "new_t2 = torch.stack((t,t,t),dim=1)\n",
        "print(new_t1,new_t1.shape)\n",
        "print(new_t2,new_t2.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_6oZSafwk-3",
        "outputId": "fa07bdfb-a247-4942-9f4d-eb5cc95dc6d2"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t的shape是： torch.Size([2, 3])\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [1, 2, 3],\n",
            "        [4, 5, 6]]) torch.Size([2, 3]) torch.Size([4, 3])\n",
            "tensor([[[1, 2, 3],\n",
            "         [4, 5, 6]],\n",
            "\n",
            "        [[1, 2, 3],\n",
            "         [4, 5, 6]],\n",
            "\n",
            "        [[1, 2, 3],\n",
            "         [4, 5, 6]]]) torch.Size([3, 2, 3])\n",
            "tensor([[[1, 2, 3],\n",
            "         [1, 2, 3],\n",
            "         [1, 2, 3]],\n",
            "\n",
            "        [[4, 5, 6],\n",
            "         [4, 5, 6],\n",
            "         [4, 5, 6]]]) torch.Size([2, 3, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.ones((2,7))\n",
        "# 给定划分个数，以及维度\n",
        "torch_tensor = torch.chunk(a,chunks=3,dim=1)\n",
        "print(torch_tensor)\n",
        "# split 是给定划分的长度（长度也可以通过列表设置） 以及维度\n",
        "torch_tensor1 = torch.split(a,split_size_or_sections=3,dim=1)\n",
        "print(torch_tensor1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvweJWlYwlBe",
        "outputId": "b2f2a349-4d3d-4a4e-a4c0-04b0d675c678"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]]), tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]]), tensor([[1.],\n",
            "        [1.]]))\n",
            "(tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]]), tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]]), tensor([[1.],\n",
            "        [1.]]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# index_select 在维度索引\n",
        "a = torch.randint(0,9,size = (3,3))\n",
        "print(\"a:\",a)\n",
        "idx = torch.tensor([0,2],dtype=torch.long) #这里需要是long类型 float过不了\n",
        "indx_ten = torch.index_select(a,dim=1,index = idx)\n",
        "print(indx_ten)\n",
        "# masked_select 按照mask中的True索引，返回一维张量，mask和input的形状是一样的\n",
        "# t.ge(5) >=5 le() <= gt> lt<\n",
        "mask = a.ge(5)\n",
        "print(mask)\n",
        "ind = torch.masked_select(a,mask)\n",
        "print(ind)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqZb85UBsFqb",
        "outputId": "cf0e6471-9baf-4b06-b49b-372d2688b243"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a: tensor([[7, 5, 0],\n",
            "        [8, 7, 0],\n",
            "        [1, 2, 1]])\n",
            "tensor([[7, 0],\n",
            "        [8, 0],\n",
            "        [1, 1]])\n",
            "tensor([[ True,  True, False],\n",
            "        [ True,  True, False],\n",
            "        [False, False, False]])\n",
            "tensor([7, 5, 8, 7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reshape t和t_tensor是共享内存的\n",
        "t = torch.randperm(8)\n",
        "print(t)\n",
        "t_tensor = torch.reshape(t,shape=(-1,4,2))\n",
        "print(\"t_tesnor:\",t_tensor)\n",
        "# transpose\n",
        "t = torch.rand((2,3,4))\n",
        "print(t,t.shape)\n",
        "t_tensor = torch.transpose(t,dim0=1,dim1=2)\n",
        "print(\"t_tensor:\",t_tensor,t_tensor.shape)\n",
        "# troch.t 二维转置\n",
        "t = torch.rand((2,3))\n",
        "print(t,t.shape)\n",
        "t_tensor = torch.t(t)\n",
        "print(\"t_tensor:\",t_tensor,t_tensor.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2DTX849sFyo",
        "outputId": "f9771c81-07f6-46c8-cec8-d137762eb374"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([6, 3, 0, 4, 1, 7, 5, 2])\n",
            "t_tesnor: tensor([[[6, 3],\n",
            "         [0, 4],\n",
            "         [1, 7],\n",
            "         [5, 2]]])\n",
            "tensor([[[0.9280, 0.6586, 0.0381, 0.8449],\n",
            "         [0.0300, 0.1526, 0.2061, 0.4123],\n",
            "         [0.3656, 0.2635, 0.5037, 0.2615]],\n",
            "\n",
            "        [[0.0818, 0.6446, 0.0796, 0.6990],\n",
            "         [0.1969, 0.3755, 0.8533, 0.6700],\n",
            "         [0.6178, 0.1113, 0.4883, 0.1038]]]) torch.Size([2, 3, 4])\n",
            "t_tensor: tensor([[[0.9280, 0.0300, 0.3656],\n",
            "         [0.6586, 0.1526, 0.2635],\n",
            "         [0.0381, 0.2061, 0.5037],\n",
            "         [0.8449, 0.4123, 0.2615]],\n",
            "\n",
            "        [[0.0818, 0.1969, 0.6178],\n",
            "         [0.6446, 0.3755, 0.1113],\n",
            "         [0.0796, 0.8533, 0.4883],\n",
            "         [0.6990, 0.6700, 0.1038]]]) torch.Size([2, 4, 3])\n",
            "tensor([[0.4052, 0.5011, 0.4588],\n",
            "        [0.3924, 0.7506, 0.0966]]) torch.Size([2, 3])\n",
            "t_tensor: tensor([[0.4052, 0.3924],\n",
            "        [0.5011, 0.7506],\n",
            "        [0.4588, 0.0966]]) torch.Size([3, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# squeeze 压缩长度为1的维度\n",
        "t = torch.rand((1,2,3,1))\n",
        "t_sq = torch.squeeze(t)\n",
        "print(t_sq,t_sq.shape)\n",
        "# 压缩的维度可以指定,如果不是1就不压缩\n",
        "t_sq = torch.squeeze(t,dim=0)\n",
        "print(t_sq,t_sq.shape)\n",
        "# unsqueeze 扩充维度\n",
        "t_s1 = torch.unsqueeze(t_sq,dim=0)\n",
        "print(t_s1,t_s1.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cjM_rJg0gZ-",
        "outputId": "1bfb63e8-a1cb-47b0-b7fa-f78af0ae5236"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2700, 0.2643, 0.5487],\n",
            "        [0.1172, 0.5680, 0.9336]]) torch.Size([2, 3])\n",
            "tensor([[[0.2700],\n",
            "         [0.2643],\n",
            "         [0.5487]],\n",
            "\n",
            "        [[0.1172],\n",
            "         [0.5680],\n",
            "         [0.9336]]]) torch.Size([2, 3, 1])\n",
            "tensor([[[[0.2700],\n",
            "          [0.2643],\n",
            "          [0.5487]],\n",
            "\n",
            "         [[0.1172],\n",
            "          [0.5680],\n",
            "          [0.9336]]]]) torch.Size([1, 2, 3, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ie3b9LnCxoHd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **张量的数学运算**\n",
        "\n",
        "1. 加减乘除，对数指数幂函数，三角函数 \n",
        "  1. **torch.add(input, alpha=1, other, out=None)：逐元素计算input+alpha * other。注意人家这里有个 alpha，叫做乘项因子。类似权重的个东西。**这个东西让计算变得更加简洁， 比如线性回归我们知道有个 y = wx + b， 在这里直接一行代码torch.add(b, w, x) 就搞定。类似的还有两个方法：\n",
        "  2. torch.addcdiv(input, value=1, tensor1, tensor2, out=None)。这个实现了\n",
        "  input + value*(tensor1/tensor2)\n",
        "  3. torch.addcmul(input, value=1, tensor1, tensor2, out=None)：这个实现了\n",
        "  input + value*tensor1*tensor2\n",
        "  4. sub（减法） div（除法） mul(乘法) "
      ],
      "metadata": {
        "id": "T2z2egN1xoMI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.rand((4,))# 一维张量就是向量\n",
        "t1 = torch.reshape(t,shape=(4,1)) \n",
        "print(t,t1)\n",
        "t2 = torch.ones_like(t)\n",
        "print(t2)\n",
        "t2 = torch.add(t,10,t2)\n",
        "print(t2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXwDI4S_8LSp",
        "outputId": "cac60f8c-1b58-4662-c9e8-86964183b602"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.3631, 0.5902, 0.0387, 0.4572]) tensor([[0.3631],\n",
            "        [0.5902],\n",
            "        [0.0387],\n",
            "        [0.4572]])\n",
            "tensor([1., 1., 1., 1.])\n",
            "tensor([10.3631, 10.5902, 10.0387, 10.4572])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: This overload of add is deprecated:\n",
            "\tadd(Tensor input, Number alpha, Tensor other, *, Tensor out)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd(Tensor input, Tensor other, *, Number alpha, Tensor out) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1050.)\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 现行回归实现\n",
        "x = torch.rand(20,1)*10\n",
        "y = 2*x + (5 + torch.randn((20,1)))\n",
        "\n",
        "lr = 10**-3\n",
        "\n",
        "#构建线性回归的参数 需要求梯度\n",
        "w = torch.rand((1),requires_grad=True)  \n",
        "b = torch.zeros((1),requires_grad=True)\n",
        "\n",
        "for iter in range(100):\n",
        "  # 前向传播\n",
        "  wx = torch.mul(w,x)\n",
        "  y_pred = torch.add(wx,b)\n",
        "\n",
        "  # 计算loss\n",
        "  loss = (0.5 *(y-y_pred)**2).mean()\n",
        "\n",
        "  # 反向传播\n",
        "  loss.backward()\n",
        "\n",
        "  # g更新参数 # 这种_的加法操作时从自身减，相当于-=\n",
        "  b.data.sub_(lr * b.grad) \n",
        "  w.data.sub_(lr * w.grad)\n",
        "\n",
        "  # 梯度清零\n",
        "  w.grad.data.zero_()\n",
        "  b.grad.data.zero_()\n",
        "  \n",
        "  # rint(w.data, b.data)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(x,y)\n",
        "# plt.show(x,w.data*x+b.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "vANyzFSH8-Gs",
        "outputId": "1b1f8ffe-b66e-40e0-edd4-a64105318399"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f68bd4c50d0>]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!pip install transformers datasets accelerate \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 直接利用外部的数据集划分为训练集和验证集，不使用比赛的数据集进行预训练\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/train.csv\")\n",
        "df['severe_toxic'] = df.severe_toxic * 2\n",
        "# 进行标签相加\n",
        "df['y'] = (df[['toxic', 'severe_toxic', 'obscene', 'threat',\n",
        "       'insult', 'identity_hate']].sum(axis = 1)).astype(int)\n",
        "df['y'] = df['y'] / df['y'].max()\n",
        "df = df.rename(columns = {'comment_text':'exceprt'})\n",
        "df = df[['exceprt','y']]\n",
        "df.sample(5)\n",
        "print(len(df))\n",
        "df.to_csv(f'/content/sample_data/train.csv', index=False)\n",
        "# df_train,df_test = train_test_split(df,test_size = 0.3,random_state=2)\n",
        "# df_train.to_csv(f'/kaggle/working/train.csv', index=False)\n",
        "# df_test.to_csv(f'/kaggle/working/test.csv', index=False)\n",
        "train = pd.read_csv('/content/sample_data/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/comments_to_score.csv')\n",
        "\n",
        "mlm_data = train[['exceprt']]\n",
        "mlm_data = mlm_data.rename(columns={'exceprt':'text'})\n",
        "mlm_data.to_csv('mlm_data.csv', index=False)\n",
        "\n",
        "mlm_data_val = test[['text']]\n",
        "mlm_data_val = mlm_data_val.rename(columns={'text':'text'})\n",
        "mlm_data_val.to_csv('mlm_data_val.csv', index=False)\n",
        "import argparse\n",
        "import logging\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "\n",
        "\n",
        "import datasets\n",
        "from datasets import load_dataset\n",
        "from tqdm.auto import tqdm\n",
        "from accelerate import Accelerator\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import transformers\n",
        "from transformers import (\n",
        "    CONFIG_MAPPING, \n",
        "    MODEL_MAPPING, \n",
        "    AdamW, \n",
        "    AutoConfig, \n",
        "    AutoModelForMaskedLM, \n",
        "    AutoTokenizer, \n",
        "    DataCollatorForLanguageModeling, \n",
        "    SchedulerType, \n",
        "    get_scheduler, \n",
        "    set_seed\n",
        ")\n",
        "\n",
        "# getlogger日志模块对象，日志输出，等级是从debug-critical从低到高，setlevel是设置日志输出等级\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "MODEL_CONFIG_CLASSES = list(MODEL_MAPPING.keys())\n",
        "MODEL_TYPES = tuple(conf.model_type for conf in MODEL_CONFIG_CLASSES)\n",
        "\n",
        "# from pprint import pprint\n",
        "# pprint(MODEL_TYPES, width=3, compact=True)\n",
        "class TrainConfig:\n",
        "    train_file= 'mlm_data.csv'\n",
        "    validation_file = 'mlm_data.csv'\n",
        "    validation_split_percentage= 5\n",
        "    pad_to_max_length= True\n",
        "    model_name_or_path= 'roberta-base'\n",
        "    config_name= 'roberta-base'\n",
        "    tokenizer_name= 'roberta-base'\n",
        "    use_slow_tokenizer= True\n",
        "    per_device_train_batch_size= 4\n",
        "    per_device_eval_batch_size= 4\n",
        "    learning_rate= 5e-5\n",
        "    weight_decay= 0.0\n",
        "    num_train_epochs= 1 # change to 5\n",
        "    max_train_steps= None\n",
        "    gradient_accumulation_steps= 1\n",
        "    lr_scheduler_type= 'constant_with_warmup'\n",
        "    num_warmup_steps= 0\n",
        "    output_dir= 'output'\n",
        "    seed= 2021\n",
        "    model_type= 'roberta'\n",
        "    max_seq_length= None\n",
        "    line_by_line= False\n",
        "    preprocessing_num_workers= 4\n",
        "    overwrite_cache= True\n",
        "    mlm_probability= 0.15\n",
        "\n",
        "config = TrainConfig()\n",
        "\n",
        "if config.train_file is not None:\n",
        "    # 拿到文件名的后缀，然后声明\n",
        "    extension = config.train_file.split(\".\")[-1]\n",
        "    assert extension in [\"csv\", \"json\", \"txt\"], \"`train_file` should be a csv, json or txt file.\"\n",
        "if config.validation_file is not None:\n",
        "    extension = config.validation_file.split(\".\")[-1]\n",
        "    assert extension in [\"csv\", \"json\", \"txt\"], \"`validation_file` should be a csv, json or txt file.\"\n",
        "if config.output_dir is not None:\n",
        "    # 递归创建目录，第一个参数是path \n",
        "    os.makedirs(config.output_dir, exist_ok=True)\n",
        "    def main():\n",
        "    args = TrainConfig()\n",
        "    accelerator = Accelerator()\n",
        "    # 上面已经初始化了函数，logging.basicConfig函数中，可以指定日志的输出格式format，这个参数可以输出很多有用的信息\n",
        "    logging.basicConfig(\n",
        "        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
        "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
        "        level=logging.INFO,\n",
        "    )\n",
        "    logger.info(accelerator.state)\n",
        "    logger.setLevel(logging.INFO if accelerator.is_local_main_process else logging.ERROR)\n",
        "\n",
        "    if accelerator.is_local_main_process:\n",
        "        datasets.utils.logging.set_verbosity_warning()\n",
        "        transformers.utils.logging.set_verbosity_info()\n",
        "    else:\n",
        "        datasets.utils.logging.set_verbosity_error()\n",
        "        transformers.utils.logging.set_verbosity_error()\n",
        "    if args.seed is not None:\n",
        "        set_seed(args.seed)\n",
        "\n",
        "    data_files = {}\n",
        "    if args.train_file is not None:\n",
        "        data_files[\"train\"] = args.train_file\n",
        "    if args.validation_file is not None:\n",
        "        data_files[\"validation\"] = args.validation_file\n",
        "    extension = args.train_file.split(\".\")[-1]\n",
        "    if extension == \"txt\":\n",
        "        extension = \"text\"\n",
        "    # 加载数据，训练和测试集，字典表示\n",
        "    raw_datasets = load_dataset(extension, data_files=data_files)\n",
        "    \n",
        "    # 这部分是加载模型的判断\n",
        "    if args.config_name:\n",
        "    # transformers.AutoConfig 使用类方法 from_pretrained 加载模型配置，参数既可以为模型名称，也可以为具体文件。\n",
        "        config = AutoConfig.from_pretrained(args.config_name)\n",
        "    elif config.model_name_or_path:\n",
        "        config = AutoConfig.from_pretrained(args.model_name_or_path)\n",
        "    else:\n",
        "        # 使用 CONFIG_MAPPING 是避免if-else语句过多，\n",
        "        config = CONFIG_MAPPING[args.model_type]()\n",
        "        logger.warning(\"You are instantiating a new config instance from scratch.\")\n",
        "\n",
        "    if args.tokenizer_name:\n",
        "        tokenizer = AutoTokenizer.from_pretrained(args.tokenizer_name, use_fast=not args.use_slow_tokenizer)\n",
        "    elif args.model_name_or_path:\n",
        "        tokenizer = AutoTokenizer.from_pretrained(args.model_name_or_path, use_fast=not args.use_slow_tokenizer)\n",
        "    else:\n",
        "        raise ValueError(\n",
        "            \"You are instantiating a new tokenizer from scratch. This is not supported by this script.\"\n",
        "            \"You can do it from another script, save it, and load it from here, using --tokenizer_name.\"\n",
        "        )\n",
        "    \n",
        "    if args.model_name_or_path:\n",
        "        #  ForMaskedLM  看一下MLM这些模型，屏蔽语言模型\n",
        "        model = AutoModelForMaskedLM.from_pretrained(\n",
        "            \n",
        "            args.model_name_or_path,\n",
        "            from_tf=bool(\".ckpt\" in args.model_name_or_path),\n",
        "            config=config,\n",
        "        )\n",
        "    else:\n",
        "        logger.info(\"Training new model from scratch\")\n",
        "        model = AutoModelForMaskedLM.from_config(config)\n",
        "    \n",
        "    # new_tokens = ['COVID', 'hospitalization']  num_added_toks = tokenizer.add_tokens(new_tokens)\n",
        "    # 在模型中添加自己文件中的token，通过model.resize_token_embeddings方法，随机初始化了一个权重，\n",
        "    # 保存添加后的词汇：tokenizer.savepretrained  再次加载模型就会自动读取增加后的词汇。\n",
        "    model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "    column_names = raw_datasets[\"train\"].column_names\n",
        "    \n",
        "    text_column_name = \"text\" if \"text\" in column_names else column_names[0]\n",
        "\n",
        "    if args.max_seq_length is None:\n",
        "        max_seq_length = tokenizer.model_max_length\n",
        "        if max_seq_length > 1024:\n",
        "            logger.warning(\n",
        "                f\"The tokenizer picked seems to have a very large `model_max_length` ({tokenizer.model_max_length}). \"\n",
        "                \"Picking 1024 instead. You can change that default value by passing --max_seq_length xxx.\"\n",
        "            )\n",
        "            max_seq_length = 1024\n",
        "    else:\n",
        "        if args.max_seq_length > tokenizer.model_max_length:\n",
        "            logger.warning(\n",
        "                f\"The max_seq_length passed ({args.max_seq_length}) is larger than the maximum length for the\"\n",
        "                f\"model ({tokenizer.model_max_length}). Using max_seq_length={tokenizer.model_max_length}.\"\n",
        "            )\n",
        "        max_seq_length = min(args.max_seq_length, tokenizer.model_max_length)\n",
        "\n",
        "    def tokenize_function(examples):\n",
        "        # 对新的任务进行 分词，\n",
        "        return tokenizer(examples[text_column_name], return_special_tokens_mask=True)\n",
        "    \n",
        "    # 得到分词之后的数据集，经过分词之后返回的是带有 input_ids、attention_mask 和 token_type_ids的字典格式\n",
        "    # 使用Dataset.map方法，可以使数据仍返回数据集的格式，而不是字典的形式，这样可以继续对数据集进行预处理，而不是直接得到向量化的结果\n",
        "    # 分词器处理成对的句子列表，如前所述。 这将允许我们在调用 map 时使用选项 batched=True，这将大大加快向量化 实现批量化的分词\n",
        "    tokenized_datasets = raw_datasets.map(\n",
        "        tokenize_function,\n",
        "        batched=True,\n",
        "        num_proc=args.preprocessing_num_workers,\n",
        "        remove_columns=column_names,\n",
        "        load_from_cache_file=not args.overwrite_cache,\n",
        "    )\n",
        "\n",
        "    # 重新进行数据预处理的过程\n",
        "    def group_texts(examples):\n",
        "        concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
        "        total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
        "        total_length = (total_length // max_seq_length) * max_seq_length\n",
        "        result = {\n",
        "            k: [t[i : i + max_seq_length] for i in range(0, total_length, max_seq_length)]\n",
        "            for k, t in concatenated_examples.items()\n",
        "        }\n",
        "        return result\n",
        "\n",
        "    tokenized_datasets = tokenized_datasets.map(\n",
        "        group_texts,\n",
        "        batched=True,\n",
        "        num_proc=args.preprocessing_num_workers,\n",
        "        load_from_cache_file=not args.overwrite_cache,\n",
        "    )\n",
        "    # 对我们想要一起批处理的数据集的项目应用正确的填充量，动态填充 DataCollatorWithPadding、\n",
        "    # 在划分batch的时候再进行padding\n",
        "    train_dataset = tokenized_datasets[\"train\"]\n",
        "    eval_dataset = tokenized_datasets[\"validation\"]\n",
        "\n",
        "    \n",
        "    # bert的预训练模式一般分为，Masked language model (MLM)与 next sentence prediction(NSP)，主要利用MLM在自己的语料上进行预训练\n",
        "    # 预训练的模式为MLM，直接调用 DataCollatorForLanguageModeling API即可方便得以自己的语料定义生成器\n",
        "    data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=args.mlm_probability)\n",
        "    \n",
        "    # Dataset是一个包装类，用来将数据包装为Dataset类，然后传入DataLoader中，我们再使用DataLoader这个类来更加快捷的对数据进行操作。\n",
        "    # DataLoader是一个比较重要的类，它为我们提供的常用操作有：batch_size(每个batch的大小), \n",
        "    # shuffle(是否进行shuffle操作), num_workers(加载数据的时候使用几个子进程)\n",
        "    train_dataloader = DataLoader(\n",
        "        train_dataset, shuffle=True, collate_fn=data_collator, batch_size=args.per_device_train_batch_size\n",
        "    )\n",
        "    eval_dataloader = DataLoader(eval_dataset, collate_fn=data_collator, batch_size=args.per_device_eval_batch_size)\n",
        "\n",
        "    \n",
        "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
        "    optimizer_grouped_parameters = [\n",
        "        {\n",
        "            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "            \"weight_decay\": args.weight_decay,\n",
        "        },\n",
        "        {\n",
        "            \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
        "            \"weight_decay\": 0.0,\n",
        "        },\n",
        "    ]\n",
        "    optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate)\n",
        "\n",
        "    model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n",
        "        model, optimizer, train_dataloader, eval_dataloader\n",
        "    )\n",
        "\n",
        "    num_update_steps_per_epoch = math.ceil(len(train_dataloader) / args.gradient_accumulation_steps)\n",
        "    if args.max_train_steps is None:\n",
        "        args.max_train_steps = args.num_train_epochs * num_update_steps_per_epoch\n",
        "    else:\n",
        "        # 向上取整\n",
        "        args.num_train_epochs = math.ceil(args.max_train_steps / num_update_steps_per_epoch)\n",
        "\n",
        "    lr_scheduler = get_scheduler(\n",
        "        name=args.lr_scheduler_type,\n",
        "        optimizer=optimizer,\n",
        "        num_warmup_steps=args.num_warmup_steps,\n",
        "        num_training_steps=args.max_train_steps,\n",
        "    )\n",
        "\n",
        "    total_batch_size = args.per_device_train_batch_size * accelerator.num_processes * args.gradient_accumulation_steps\n",
        "\n",
        "    logger.info(\"***** Running training *****\")\n",
        "    logger.info(f\"  Num examples = {len(train_dataset)}\")\n",
        "    logger.info(f\"  Num Epochs = {args.num_train_epochs}\")\n",
        "    logger.info(f\"  Instantaneous batch size per device = {args.per_device_train_batch_size}\")\n",
        "    logger.info(f\"  Total train batch size (w. parallel, distributed & accumulation) = {total_batch_size}\")\n",
        "    logger.info(f\"  Gradient Accumulation steps = {args.gradient_accumulation_steps}\")\n",
        "    logger.info(f\"  Total optimization steps = {args.max_train_steps}\")\n",
        "    # Only show the progress bar once on each machine.\n",
        "    progress_bar = tqdm(range(args.max_train_steps), disable=not accelerator.is_local_main_process)\n",
        "    completed_steps = 0\n",
        "\n",
        "    for epoch in range(args.num_train_epochs):\n",
        "        model.train()\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            outputs = model(**batch)\n",
        "            loss = outputs.loss\n",
        "            loss = loss / args.gradient_accumulation_steps\n",
        "            accelerator.backward(loss)\n",
        "            if step % args.gradient_accumulation_steps == 0 or step == len(train_dataloader) - 1:\n",
        "                optimizer.step()\n",
        "                lr_scheduler.step()\n",
        "                optimizer.zero_grad()\n",
        "                progress_bar.update(1)\n",
        "                completed_steps += 1\n",
        "\n",
        "            if completed_steps >= args.max_train_steps:\n",
        "                break\n",
        "\n",
        "        model.eval()\n",
        "        losses = []\n",
        "        for step, batch in enumerate(eval_dataloader):\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**batch)\n",
        "\n",
        "            loss = outputs.loss\n",
        "            losses.append(accelerator.gather(loss.repeat(args.per_device_eval_batch_size)))\n",
        "\n",
        "        losses = torch.cat(losses)\n",
        "        losses = losses[: len(eval_dataset)]\n",
        "        perplexity = math.exp(torch.mean(losses))\n",
        "\n",
        "        logger.info(f\"epoch {epoch}: perplexity: {perplexity}\")\n",
        "\n",
        "    if args.output_dir is not None:\n",
        "        accelerator.wait_for_everyone()\n",
        "        unwrapped_model = accelerator.unwrap_model(model)\n",
        "        unwrapped_model.save_pretrained(args.output_dir, save_function=accelerator.save)\n",
        "if __name__ == \"__main__\":\n",
        "    main()      "
      ],
      "metadata": {
        "id": "ZNYfgw1GXz8k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44b8307c-3c97-41d6-b5e2-1383f974dafe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SbZCkRv7IMuj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "BAG4loyEIMxG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}